{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2: Decipherment #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Given code from Default Submission ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "from itertools import groupby\n",
    "import collections\n",
    "import pprint\n",
    "import math\n",
    "import bz2\n",
    "pp = pprint.PrettyPrinter(width=45, compact=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading language model from data/6-gram-wiki-char.lm.bz2...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from ngram import LM\n",
    "lm = LM(\"data/6-gram-wiki-char.lm.bz2\", n=6, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading Cipher from file..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    if filename[-4:] == \".bz2\":\n",
    "        with bz2.open(filename, 'rt') as f:\n",
    "            content = f.read()\n",
    "            f.close()\n",
    "    else:\n",
    "        with open(filename, 'r') as f:\n",
    "            content = f.read()\n",
    "            f.close()\n",
    "    return content\n",
    "\n",
    "cipher = read_file(\"data/cipher.txt\")\n",
    "#print(cipher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_statistics(content, cipher=True):\n",
    "    stats = {}\n",
    "    content = list(content)\n",
    "    split_content = [x for x in content if x != '\\n' and x!=' ']\n",
    "    length = len(split_content)\n",
    "    symbols = set(split_content)\n",
    "    uniq_sym = len(list(symbols))\n",
    "    freq = collections.Counter(split_content)\n",
    "    rel_freq = {}\n",
    "    for sym, frequency in freq.items():\n",
    "        rel_freq[sym] = (frequency/length)*100\n",
    "        \n",
    "    if cipher:\n",
    "        stats = {'content':split_content, 'length':length, 'vocab':list(symbols), 'vocab_length':uniq_sym, 'frequencies':freq, 'relative_freq':rel_freq}\n",
    "    else:\n",
    "        stats = {'length':length, 'vocab':list(symbols), 'vocab_length':uniq_sym, 'frequencies':freq, 'relative_freq':rel_freq}\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Baseline Solution ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, a list of all possible plaintext symbols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "Ve = [chr(i) for i in range(ord('a'),ord('z')+1)]\n",
    "print(Ve)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must first create a few functions to help us implement a baseline solution using a beam search algorithm.\n",
    "The functions are derived from the pseudocode provided in assignment 2. Brief descriptions precede each function and will be used together in the function named `beam_search` defined later in the file.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`find_ext_order` will return a list of ordered ciphertext symbols according to highest frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ext_order(content):\n",
    "    \"\"\"\n",
    "    Finds the ordering of letters for ext_order for highest_frquency\n",
    "    \n",
    "    parameters:\n",
    "    -----------\n",
    "    content: str\n",
    "        The entire (ciphertext) string to be transformed into a list of\n",
    "        symbols to be iterated over in order in the beam search.\n",
    "    \n",
    "    returns:\n",
    "    ----------\n",
    "    ext_order: list of str\n",
    "        list of ciphertext symbols returned in descending order of \n",
    "        highest frequency\n",
    "        \n",
    "    \"\"\"\n",
    "    content = list(content)\n",
    "    split_content = [x for x in content if x != '\\n' and x!=' ']\n",
    "    symbols = set(split_content)\n",
    "    freq = list(collections.Counter(split_content).items())\n",
    "    freq.sort(key=lambda x: x[1], reverse=True)\n",
    "    ext_order = [sym for sym,count in freq]\n",
    "    return ext_order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`histogram_prune` will keep the best `n_keep` scoring hypotheses and will prune the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram_prune(Ht, n_keep=1):\n",
    "    \"\"\"\n",
    "    keeps the `n_keep` best scoring hypotheses and prunes the rest\n",
    "    \n",
    "    parameters:\n",
    "    -----------\n",
    "        Ht: list of tup(set, float)\n",
    "            Hypotheses for matched plaintext and ciphertext symbols (set)\n",
    "            along with an overall score (float) \n",
    "        n_keep: int\n",
    "            How many hypotheses to keep after pruning lower scoring options\n",
    "    returns:\n",
    "    -----------\n",
    "        best_phis: list of tuples of sets(of tuples)\n",
    "            returns the n_keep best mappings as well as score\n",
    "            [({('a','A'), ('b','B')}, 0.8), ({('a','A'), ('g','B')}, 0.6)]\n",
    "    \"\"\"\n",
    "    Ht_sort = sorted(Ht, key=lambda x: x[1], reverse=True)\n",
    "    best_phis = Ht_sort[:n_keep]\n",
    "    return best_phis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`winner` Returns the best scoring phi in Hs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def winner(Hs):\n",
    "    \"\"\"Returns the best scoring phi in Hs\n",
    "    parameters:\n",
    "    -----------\n",
    "        Hs: List of tup\n",
    "            list of tuples of the form (phi, score) where phi is a \n",
    "            set of potential mappings and score is the log \n",
    "            probability score of such a mapping\n",
    "    \n",
    "    returns:\n",
    "    -----------\n",
    "        best_phi: set of tuples\n",
    "            Highest scoring mapping \n",
    "    \"\"\"\n",
    "    best_phi = [(phi, score) for phi,score in Hs if score == max([s for p,s in Hs])]\n",
    "    return best_phi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ext_limits_check` checks the tuples in phi_prime and returns how many times the alphacharacter e, has been mapped to a ciphertext character f in the set phi_prime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ext_limits_check(phi_prime, e):\n",
    "    \"\"\"\n",
    "    Checks the tuples in phi_prime and returns how many times the\n",
    "    alphacharacter e, has been mapped to a ciphertext character f\n",
    "    in the set phi_prime\n",
    "    \n",
    "    parameters:\n",
    "    -----------\n",
    "        phi_prime: set of tuples\n",
    "            set of tuples of the form (e,f) where e is is an \n",
    "            alpha-character and f is a ciphertext character\n",
    "        e: str\n",
    "            plaintext character e to be counted in phi_prime\n",
    "    returns:\n",
    "    -----------\n",
    "        e_count: int\n",
    "            the number of times the plaintext character e has\n",
    "            occured in the set phi_prime in the position (e,f)\n",
    "    \"\"\"\n",
    "    e_s = [e for e,f in phi_prime]\n",
    "    e_count = e_s.count(e)\n",
    "    return(e_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`g` is a transformation function 'g' returns a sequence in plaintext as well as the corresponding bitstring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g(cipher, mappings):\n",
    "    \"\"\"\n",
    "    transformation function 'g' returns a sequence in plaintext\n",
    "    as well as the corresponding bitstring. To be used in the \n",
    "    score_bitstring function from the ngram.py file.\n",
    "    \n",
    "    parameters:\n",
    "    ------------\n",
    "        cipher: str\n",
    "            entire ciphertext symbol\n",
    "        mappings: \n",
    "    returns:\n",
    "    -----------\n",
    "        seq: str\n",
    "            partially mapped solution using mappings if the mapping is defined,\n",
    "            else it returns a dummy symbol '_' \n",
    "        bitstring_span: str\n",
    "            bitstring representation of mapped symbols. \n",
    "            'o' if the symbol has already been deciphered \n",
    "            '.' if the symbol is yet to be deciphered \n",
    "    \"\"\"\n",
    "    seq = \"\"\n",
    "    bitstring_span = \"\" # a little confused about this\n",
    "    match_found = False\n",
    "    for symbol in cipher:\n",
    "        for e,f in mappings:\n",
    "            if symbol == f:\n",
    "                bitstring_span += \"o\"\n",
    "                seq += e #append plain text alphabet\n",
    "                match_found=True\n",
    "        if not match_found:\n",
    "            seq += \"_\"\n",
    "            bitstring_span += \".\"\n",
    "        else:\n",
    "            match_found=False\n",
    "    return seq, bitstring_span"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`score` uses the `score_bitstring` functionfrom the language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(seq, bitstring):\n",
    "    \"\"\"Score function using the `score_bitstring` function\n",
    "    from the language model\n",
    "    \n",
    "    returns:\n",
    "    --------\n",
    "    log probability score of the partially deciphered string\n",
    "    \"\"\"\n",
    "    return lm.score_bitstring(seq, bitstring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of beam search pseudocode! ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search(Ve, ext_order, cipher, ext_limits=1, n_keep=1):\n",
    "    \"\"\"\n",
    "    parameters:\n",
    "    ------------\n",
    "        Ve: list of str\n",
    "            list of plaintext candidates\n",
    "        ext_order: list of str\n",
    "            list of cipher symbols sorted by their frequencies in the ciphertext\n",
    "        cipher: str\n",
    "            cipher text loaded from file\n",
    "        ext_limits: int\n",
    "            provides a constraint for the maximum number of cipher symbols\n",
    "            that can map to each English letter. For a 1:1 substitution cipher\n",
    "            ext_limits would be 1. For a homophonic cipher it should be \n",
    "            greater than 1. \n",
    "        n_keep: int\n",
    "            number of 'best' candidate mappings to keep while traversing the tree\n",
    "    returns:\n",
    "    ------------\n",
    "        winner(Hs): set of tuples\n",
    "            Best mapping according to the highest score\n",
    "    \"\"\"\n",
    "    cipher = cipher.replace('\\n','').strip(' ') # remove newlines and spaces from the cipher\n",
    "    Vf_size = len(ext_order)\n",
    "    Hs = list()\n",
    "    Ht = list()\n",
    "    cardinality = 0\n",
    "    Hs.append((set(),0))\n",
    "    while cardinality < Vf_size:\n",
    "        f = ext_order[cardinality]\n",
    "        for phi, s in Hs:\n",
    "            for e in Ve:\n",
    "                phi_prime = phi.union({(e,f)})\n",
    "                e_count = ext_limits_check(phi_prime, e)\n",
    "                if e_count <= ext_limits:\n",
    "                    sequence, bitstring = g(cipher, phi_prime)\n",
    "                    Ht.append((phi_prime, score(sequence, bitstring)))\n",
    "        cardinality += 1\n",
    "        Ht = histogram_prune(Ht, n_keep=n_keep)\n",
    "        if Ht != []:\n",
    "            Hs = Ht.copy()\n",
    "        Ht = list()\n",
    "    return winner(Hs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First shot at using baseline solution..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score is: -607.8314711340004\n"
     ]
    }
   ],
   "source": [
    "cipher = read_file(\"data/cipher.txt\")\n",
    "ext_order = find_ext_order(cipher)\n",
    "ext_limits = 3\n",
    "n_keep = 1000\n",
    "matches = beam_search(Ve, ext_order, cipher, ext_limits, n_keep)\n",
    "print(\"The score is: {}\".format(matches[0][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Thoughts ###  \n",
    "We tried various parameters including ext_limits in [1, 2, 3, 4] and n_keep in [1, 100, 1000, 10000] with varying success.   \n",
    "  \n",
    "We have also attempted a higher n_keep in order to keep more potential options at each iteration. This clearly was taking a long time and other potential improvements could be made before another attempt that required so much computing power. There also exists room to improve the efficiency of the baseline solution by potentially implementing a priority queue to keep track of scores instead of continuously sorting lists.  \n",
    "  \n",
    "There were clearly issues with the baseline solution that could be improved. Upon increasing ext_limits we saw an increase in more frequent letters being mapped multiple times. For example, this caused a decipherment with many 'e's and 't's included. This was clearly not english. This must be further explored in order to choose the best ext_limits. \n",
    "  \n",
    "The ordering of ext_order plays into the problem as well. If more frequent letters are checked first, they tend to have a higher mapping probability and are mapped immediately. This does not allow for less frequent but plausible letters to be considered; they are pruned early on and never considered again. So far, this raises two potential issues: the ordering of ext_order is thus an important consideration as well as our choice for ext_limits.  \n",
    "\n",
    "This leads us to explore options to potentially improve the following:  \n",
    "- improving the ordering of ext_order\n",
    "- potentially implementing a different `ext_limits`\n",
    "- improving runtime of algorithm through above methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving Baseline ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improving EXT_ORDER ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used two approaches to improve our ext_order beacuse we believe by exploring these ideas we can decrease the overall execution time and improve the quality of our decipherment:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Firstly, instead of taking the ext_order according to the frequencies of the letters appearing in the cipher, we implemented an ext_order based on the length of the longest deciphered string. For the first character in the ext_order, it chooses the character with the highest frequency in the cipher text as a starting point. After that, it chooses the character next to the longest deciphered substring. So, for example, in case of cipher text: FREEZER, the first character chosen would be \"E\" (highest frequency). In the second iteration, the next character chosen would be \"Z\" because it appears next to the longest deciphered susequence, \"EE\" in this case. This approach performed exceptionally well for 1:1 mapping, but did not do well for the homophonic ciphers.  \n",
    "   \n",
    "   \n",
    "- Secondly, we used the Improved Decipherment of Homophonic Ciphers to weight each cipher symbols to generate a better ext_order based on thier partial decipherment. We used a weighted frequency based approach that orders the symbols based on the maximum number of partial decipherment present. This is intiative because this gives us a higher degree of confidance to pick a better decipherment using previous characters (on every itteration).\n",
    "\n",
    "We also attempted shuffling the order of ext_order as well as ordering by reverse frequency. These did not show promising results. A final ordering was chosen to be a reverse observed order of the cipher text, explained in more detail in our final solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First implementation of ext_order ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def len_iter(items):\n",
    "    \"\"\"returns the count of longest deciphered sequence (marked by '_') \"\"\"\n",
    "    return sum(1 for _ in items)\n",
    "\n",
    "def choose_next_symbol(cipher_text):\n",
    "    \"\"\"chooses the next ciphertext symbol to attempt to decipher based on longest sequence\"\"\"\n",
    "    max_len = max(len_iter(run) for val, run in groupby(cipher_text) if val == \"_\")\n",
    "    count = 0\n",
    "    for idx, symbol in enumerate(cipher_text):\n",
    "        if symbol == \"_\":\n",
    "            count += 1\n",
    "            if count == max_len:\n",
    "                return idx + 1\n",
    "        else:\n",
    "            count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search_1(Ve, ext_order, cipher, ext_limits=1, n_keep=1):\n",
    "    \"\"\"\n",
    "        beam_search implementing alternative ext_order\n",
    "    \"\"\"\n",
    "    cipher = cipher.replace('\\n','').strip(' ') # remove newlines and spaces from the cipher\n",
    "    Vf_size = len(ext_order)\n",
    "    Hs = list()\n",
    "    Ht = list()\n",
    "    cardinality = 0\n",
    "    Hs.append((set(),0))\n",
    "    vf = cipher\n",
    "    \n",
    "    while cardinality < Vf_size:\n",
    "        if cardinality == 0:\n",
    "            idx = cardinality\n",
    "            f = ext_order[idx]\n",
    "        else:\n",
    "            idx = choose_next_symbol(vf)\n",
    "            \n",
    "            if idx == len(cipher):\n",
    "                f = ext_order[0]\n",
    "            else:        \n",
    "                f = vf[idx]\n",
    "        \n",
    "        ext_order.remove(f)    \n",
    "        vf = vf.replace(f, \"_\")\n",
    "        \n",
    "        for phi, s in Hs:\n",
    "            for e in Ve:\n",
    "                phi_prime = phi.union({(e,f)})\n",
    "                e_count = ext_limits_check(phi_prime, e)\n",
    "                if e_count <= ext_limits:\n",
    "                    sequence, bitstring = g(cipher, phi_prime)\n",
    "                    Ht.append((phi_prime, score(sequence, bitstring)))\n",
    "        cardinality += 1\n",
    "        Ht = histogram_prune(Ht, n_keep=n_keep)\n",
    "        if Ht != []:\n",
    "            Hs = Ht.copy()\n",
    "        Ht = list()\n",
    "    return winner(Hs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score is: -746.1215271339094\n"
     ]
    }
   ],
   "source": [
    "cipher = read_file(\"data/cipher.txt\")\n",
    "ext_order = find_ext_order(cipher)\n",
    "ext_limits = 2\n",
    "n_keep = 100\n",
    "matches = beam_search_1(Ve, ext_order, cipher, ext_limits, n_keep)\n",
    "print(\"The score is: {}\".format(matches[0][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second implementation of ext_order ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def improved_ext_order(ext_order, partial_decipher, processed_list):\n",
    "    \"\"\"\n",
    "    Uses a weighted frequency based approach that orders \n",
    "    the symbols based on the maximum number of partial \n",
    "    decipherment present\n",
    "    \n",
    "    parameters:\n",
    "    -----------\n",
    "        ext_order: list \n",
    "            (list of) cipher symbols, ordered by weights \n",
    "        partial_decipher: str\n",
    "            partial decipherment of the cipher text generated\n",
    "        processed_list: list\n",
    "            contains list of cipher symbols alread processed \n",
    "            by the beam search\n",
    "    returns:\n",
    "    -----------\n",
    "        new_ext_order: list\n",
    "            returns the new ext_order ordered by the weights\n",
    "    \"\"\"    \n",
    "    weights = (1.0,1.0,1.0,1.0,2.0,3.0)\n",
    "    n_order_occurance_dict = dict()\n",
    "    symbol_weights = dict()\n",
    "    for symbol in ext_order:\n",
    "        n_order_occurance_dict[symbol]={\"1_gram_freq\":0,\n",
    "                                        \"2_gram_freq\":0,\n",
    "                                        \"3_gram_freq\":0,\n",
    "                                        \"4_gram_freq\":0,\n",
    "                                        \"5_gram_freq\":0,\n",
    "                                        \"6_gram_freq\":0}\n",
    "        symbol_weights[symbol]=0\n",
    "    \n",
    "    cipher_text_positions = []\n",
    "    prev_position_value = None\n",
    "    last_cipher_char_index = -1\n",
    "    \n",
    "    current_index = 0\n",
    "    for char in partial_decipher:\n",
    "\n",
    "        if char in ext_order:\n",
    "            cipher_text_positions.append(True)\n",
    "        else:\n",
    "            cipher_text_positions.append(False)\n",
    "\n",
    "        if prev_position_value == False and cipher_text_positions[-1] == True:\n",
    "        \n",
    "            no_of_plaintext = current_index - last_cipher_char_index - 1\n",
    "            \n",
    "            if no_of_plaintext >= 1:\n",
    "                n_order_occurance_dict[char][\"1_gram_freq\"] = n_order_occurance_dict[char][\"1_gram_freq\"] + 1\n",
    "            \n",
    "            if no_of_plaintext >= 2:\n",
    "                n_order_occurance_dict[char][\"2_gram_freq\"] = n_order_occurance_dict[char][\"2_gram_freq\"] + 1\n",
    "                \n",
    "            if no_of_plaintext >= 3:\n",
    "                n_order_occurance_dict[char][\"3_gram_freq\"] = n_order_occurance_dict[char][\"3_gram_freq\"] + 1\n",
    "        \n",
    "            if no_of_plaintext >= 4:\n",
    "                n_order_occurance_dict[char][\"4_gram_freq\"] = n_order_occurance_dict[char][\"4_gram_freq\"] + 1\n",
    "            \n",
    "            if no_of_plaintext >= 5:\n",
    "                n_order_occurance_dict[char][\"5_gram_freq\"] = n_order_occurance_dict[char][\"5_gram_freq\"] + 1\n",
    "                \n",
    "            if no_of_plaintext >= 6:\n",
    "                n_order_occurance_dict[char][\"6_gram_freq\"] = n_order_occurance_dict[char][\"6_gram_freq\"] + 1\n",
    "                    \n",
    "            #print(char,n_order_occurance_dict[char])\n",
    "    \n",
    "        if prev_position_value == True and cipher_text_positions[-1] == False:\n",
    "            last_cipher_char_index = current_index - 1\n",
    "\n",
    "            \n",
    "        prev_position_value = cipher_text_positions[-1]\n",
    "        current_index = current_index + 1\n",
    "        \n",
    "    for symbol,freq_dict in n_order_occurance_dict.items():\n",
    "        total_weight = 0\n",
    "#         print(\"calcualting for {}\".format(symbol))\n",
    "        for order,value in freq_dict.items():\n",
    "            if order == \"1_gram_freq\":\n",
    "                total_weight = total_weight + value*weights[0]\n",
    "#                 print(\"First 1st gram weight {}\".format(value*weights[0]))\n",
    "            \n",
    "            if order == \"2_gram_freq\":\n",
    "                total_weight = total_weight + value*weights[1]\n",
    "#                 print(\"2 gram weight {}\".format(value*weights[1]))\n",
    "                \n",
    "            if order == \"3_gram_freq\":\n",
    "                total_weight = total_weight + value*weights[2]\n",
    "#                 print(\"3 gram weight {}\".format(value*weights[2]))\n",
    "                \n",
    "            if order == \"4_gram_freq\":\n",
    "                total_weight = total_weight + value*weights[3]\n",
    "#                 print(\"4 gram weight {}\".format(value*weights[3]))\n",
    "                \n",
    "            if order == \"5_gram_freq\":\n",
    "                total_weight = total_weight + value*weights[4]\n",
    "#                 print(\"5 gram weight {}\".format(value*weights[4]))\n",
    "                \n",
    "            if order == \"6_gram_freq\":\n",
    "                total_weight = total_weight + value*weights[5]\n",
    "#                 print(\" 6 gram weight {}\".format(value*weights[5]))\n",
    "                \n",
    "#             print(\"total weight weight {}\".format(total_weight))\n",
    "                \n",
    "       \n",
    "        symbol_weights[symbol]=total_weight\n",
    "        \n",
    "    #assign 0 to symbols in processed list\n",
    "    for symbol, value in symbol_weights.items():\n",
    "        if symbol in processed_list:\n",
    "            symbol_weights[symbol]=0\n",
    "    \n",
    "    sorted_by_value = sorted(symbol_weights.items(), key=lambda kv: kv[1])\n",
    "    sorted_by_value.reverse()\n",
    "\n",
    "    new_ext_order = []\n",
    "    \n",
    "    for val in sorted_by_value:\n",
    "        new_ext_order.append(val[0])\n",
    "    \n",
    "    #print(new_ext_order)\n",
    "    return new_ext_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search_2(Ve, ext_order, cipher, ext_limits=1, n_keep=1):\n",
    "    Vf_size = len(ext_order)\n",
    "    Hs = list()\n",
    "    Ht = list()\n",
    "    cardinality = 0\n",
    "    Hs.append((set(),0))\n",
    "    processed_list=[]\n",
    "    if ext_limits > Vf_size or ext_limits < 1:\n",
    "        print(\"Error: choose a different number for `ext_limits`.\\nMust be between 1 and {}\".format(Vf_size))\n",
    "        return\n",
    "    else:\n",
    "        while cardinality < Vf_size:\n",
    "            f = ext_order[0]\n",
    "            for phi, s in Hs:\n",
    "                for e in Ve:\n",
    "                    phi_prime = phi.union({(e,f)})\n",
    "                    e_count = ext_limits_check(phi_prime, e)\n",
    "                    if e_count <= ext_limits:\n",
    "                        sequence, bitstring = g(cipher, phi_prime)\n",
    "                        Ht.append((phi_prime, score(sequence, bitstring)))\n",
    "                        ext_order = improved_ext_order(ext_order, sequence, processed_list)\n",
    "                \n",
    "            processed_list.append(f)\n",
    "            cardinality += 1\n",
    "            # When all plaintext letters have been mapped according to ext_limits\n",
    "            if(cardinality > ext_limits*len(Ve)):\n",
    "                break\n",
    "            Hs = histogram_prune(Ht, n_keep=n_keep)\n",
    "            Ht = list()\n",
    "        return winner(Hs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score is: -643.8926796859997\n"
     ]
    }
   ],
   "source": [
    "cipher = read_file(\"data/cipher.txt\")\n",
    "ext_order = find_ext_order(cipher)\n",
    "ext_limits = 3\n",
    "n_keep = 100\n",
    "matches = beam_search_2(Ve, ext_order, cipher, ext_limits, n_keep)\n",
    "print(\"The score is: {}\".format(matches[0][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improve EXT_LIMITS ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We implemented a solution for variable ext_limits, that allows for different ext_limits depending on the plaintext symbol.This results in less freqent letters such as 'x' and 'z' to have ext_limits of 1 and allows for more freqent letters to be mapped more than once. This follows the logic that if a letter occurs less frequently in english, it is less likely to appear in multiple places in the ciphertext and is not likely to have multiple cipher symbols mapped to it. Allowing for more frequent letters to have multiple mappings has a similar problem such that more frequent letters have a higher likelihood than other letters to be mapped more than once.   \n",
    "The following implementation is based on the observed frequency of letters in the english language. Frequencies are divided into bins, which determine their ext_limits. So we experimented with different ext_limits for different letters accordingly. This gave us a better score and it's usage can be seen in the final beam search algorithm.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_ext_limits():\n",
    "    plaintxt = read_file(\"data/default.wiki.txt.bz2\")\n",
    "    plaintxt_desc = get_statistics(plaintxt, cipher=False)\n",
    "\n",
    "    ext_limits = {}\n",
    "    for k, v in plaintxt_desc[\"relative_freq\"].items(): \n",
    "        if v > 5:\n",
    "            ext_limits[k] = 2\n",
    "        elif v > 0.5:\n",
    "            ext_limits[k] = 4\n",
    "        else:\n",
    "            ext_limits[k] = 1\n",
    "    return ext_limits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BEST SCORING SOLUTION ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing an `ext_order` based on an implementation for decipherment in the \"An Exact A* Method for Deciphering Letter-Substitution Ciphers\" paper suggested an ordering of reverse observed order. This would mean that from right to left from the end of the ciphertext we load the observed letters into `ext_order` exactly. This showed promising results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This new `ext_order` along with the above mentioned `new_ext_limits` function show us the best results. The following is our final implementation of the beam_search function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also saw better results by using the `score_seq` from the language model rather than scoring using the bitstring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_ext_order(content):\n",
    "    content = list(content)\n",
    "    split_content = [x for x in content if x != '\\n' and x!=' ']\n",
    "    obs_order = []\n",
    "    for x in split_content[::-1]:\n",
    "        if x not in obs_order:\n",
    "            obs_order.append(x)\n",
    "    ext_order = obs_order\n",
    "    return ext_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search_final(Ve, ext_order, cipher, ext_limits=1, n_keep=1):\n",
    "    \"\"\"\n",
    "    parameters:\n",
    "    ------------\n",
    "        Ve: list of str\n",
    "            list of plaintext candidates\n",
    "        ext_order: list of str\n",
    "            list of cipher symbols sorted by their frequencies in the ciphertext\n",
    "        cipher: str\n",
    "            cipher text loaded from file\n",
    "        ext_limits: int\n",
    "            provides a constraint for the maximum number of cipher symbols\n",
    "            that can map to each English letter. For a 1:1 substitution cipher\n",
    "            ext_limits would be 1. For a homophonic cipher it should be \n",
    "            greater than 1. \n",
    "        n_keep: int\n",
    "            number of 'best' candidate mappings to keep while traversing the tree\n",
    "    returns:\n",
    "    ------------\n",
    "        winner(Hs): set of tuples\n",
    "            Best mapping according to the highest score\n",
    "    \"\"\"\n",
    "    Vf_size = len(ext_order)\n",
    "    Hs = list()\n",
    "    Ht = list()\n",
    "    cardinality = 0\n",
    "    Hs.append((set(),0))\n",
    "    while cardinality < Vf_size:\n",
    "        f = ext_order[cardinality]\n",
    "        for phi, s in Hs:\n",
    "            for e in Ve:\n",
    "                phi_prime = phi.union({(e,f)})\n",
    "                e_count = ext_limits_check(phi_prime, e)\n",
    "                if e_count <= ext_limits[e]:\n",
    "                    sequence, bitstring = g(cipher, phi_prime)\n",
    "                    score_ = lm.score_seq(sequence)\n",
    "                    Ht.append((phi_prime, score_))\n",
    "        cardinality += 1\n",
    "        Ht = histogram_prune(Ht, n_keep=n_keep)\n",
    "        if Ht != []:\n",
    "            Hs = Ht.copy()\n",
    "        Ht = list()\n",
    "    return winner(Hs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score is: -695.3450931176005\n"
     ]
    }
   ],
   "source": [
    "cipher = read_file(\"data/cipher.txt\")\n",
    "cipher = cipher.replace('\\n','').strip(' ')\n",
    "ext_order = final_ext_order(cipher)\n",
    "n_keep = 200\n",
    "ext_limits = new_ext_limits()\n",
    "matches = beam_search_final(Ve, ext_order, cipher, ext_limits, n_keep)\n",
    "print(\"The score is: {}\".format(matches[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decipher(mapping, cipher):\n",
    "    \"\"\"Given the mapping, translates the cipher\"\"\"\n",
    "    english_text = []\n",
    "    for symbol in cipher:\n",
    "        english_text.append(mapping.get(symbol,symbol))\n",
    "    decipherment = ('').join(english_text)\n",
    "    return decipherment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = dict((y, x) for x, y in matches[0][0])\n",
    "decipherment = decipher(mapping,cipher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"decipher.txt\"\n",
    "with open(filename, \"w\") as f:\n",
    "    f.write(decipherment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elifdfallnpbdyodlelrcuyuderitbusycicycaangsbyhkychnyvfellipbfalkbmsonchidcmsbyurlectytrsucebandsothmyvbhyayomptsulbkyllhmfilltosoriacbbnddbsyanesuthhisellicbrpddbhvcoarnuddypleahryhnmcbdraecbubysbmcftockfihitbaylhnhlobrdusaucnhethimhfndvimaynfelllebrlbypicdysmkacdgcmullaihnnydofelldkfilllycosesuultdrtefellpbhbadrumysucyseldcuyboubyfellhyuruuloemofcmbghudsucmlldchipbokuluddtcbysutcarslikedlooseeadsorindaan\n"
     ]
    }
   ],
   "source": [
    "print(decipherment)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
